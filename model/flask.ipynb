{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ea2581",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting flask\n",
      "  Using cached flask-3.1.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: pyngrok in e:\\vegetable-dragon\\model\\han_env\\lib\\site-packages (7.2.8)\n",
      "Requirement already satisfied: torch in e:\\vegetable-dragon\\model\\han_env\\lib\\site-packages (2.7.0)\n",
      "Collecting kss\n",
      "  Using cached kss-6.0.4-py3-none-any.whl\n",
      "Requirement already satisfied: blinker>=1.9.0 in e:\\vegetable-dragon\\model\\han_env\\lib\\site-packages (from flask) (1.9.0)\n",
      "Requirement already satisfied: click>=8.1.3 in e:\\vegetable-dragon\\model\\han_env\\lib\\site-packages (from flask) (8.2.0)\n",
      "Requirement already satisfied: itsdangerous>=2.2.0 in e:\\vegetable-dragon\\model\\han_env\\lib\\site-packages (from flask) (2.2.0)\n",
      "Requirement already satisfied: jinja2>=3.1.2 in e:\\vegetable-dragon\\model\\han_env\\lib\\site-packages (from flask) (3.1.6)\n",
      "Requirement already satisfied: markupsafe>=2.1.1 in e:\\vegetable-dragon\\model\\han_env\\lib\\site-packages (from flask) (3.0.2)\n",
      "Requirement already satisfied: werkzeug>=3.1.0 in e:\\vegetable-dragon\\model\\han_env\\lib\\site-packages (from flask) (3.1.3)\n",
      "Requirement already satisfied: PyYAML>=5.1 in e:\\vegetable-dragon\\model\\han_env\\lib\\site-packages (from pyngrok) (6.0)\n",
      "Requirement already satisfied: filelock in e:\\vegetable-dragon\\model\\han_env\\lib\\site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in e:\\vegetable-dragon\\model\\han_env\\lib\\site-packages (from torch) (4.13.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in e:\\vegetable-dragon\\model\\han_env\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in e:\\vegetable-dragon\\model\\han_env\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: fsspec in e:\\vegetable-dragon\\model\\han_env\\lib\\site-packages (from torch) (2025.3.2)\n",
      "Requirement already satisfied: emoji==1.2.0 in e:\\vegetable-dragon\\model\\han_env\\lib\\site-packages (from kss) (1.2.0)\n",
      "Collecting pecab (from kss)\n",
      "  Using cached pecab-1.0.8-py3-none-any.whl\n",
      "Requirement already satisfied: jamo in e:\\vegetable-dragon\\model\\han_env\\lib\\site-packages (from kss) (0.4.1)\n",
      "Requirement already satisfied: hangul-jamo in e:\\vegetable-dragon\\model\\han_env\\lib\\site-packages (from kss) (1.0.1)\n",
      "Requirement already satisfied: tossi in e:\\vegetable-dragon\\model\\han_env\\lib\\site-packages (from kss) (0.3.1)\n",
      "Requirement already satisfied: distance in e:\\vegetable-dragon\\model\\han_env\\lib\\site-packages (from kss) (0.1.3)\n",
      "Requirement already satisfied: unidecode in e:\\vegetable-dragon\\model\\han_env\\lib\\site-packages (from kss) (1.4.0)\n",
      "Collecting cmudict (from kss)\n",
      "  Using cached cmudict-1.0.32-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: koparadigm in e:\\vegetable-dragon\\model\\han_env\\lib\\site-packages (from kss) (0.10.0)\n",
      "Requirement already satisfied: kollocate in e:\\vegetable-dragon\\model\\han_env\\lib\\site-packages (from kss) (0.0.2)\n",
      "Collecting bs4 (from kss)\n",
      "  Using cached bs4-0.0.2-py2.py3-none-any.whl.metadata (411 bytes)\n",
      "Requirement already satisfied: numpy in e:\\vegetable-dragon\\model\\han_env\\lib\\site-packages (from kss) (2.2.5)\n",
      "Requirement already satisfied: pytest in e:\\vegetable-dragon\\model\\han_env\\lib\\site-packages (from kss) (8.3.5)\n",
      "Requirement already satisfied: scipy in e:\\vegetable-dragon\\model\\han_env\\lib\\site-packages (from kss) (1.15.3)\n",
      "Requirement already satisfied: colorama in e:\\vegetable-dragon\\model\\han_env\\lib\\site-packages (from click>=8.1.3->flask) (0.4.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in e:\\vegetable-dragon\\model\\han_env\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: beautifulsoup4 in e:\\vegetable-dragon\\model\\han_env\\lib\\site-packages (from bs4->kss) (4.13.4)\n",
      "Requirement already satisfied: importlib-metadata>=5 in e:\\vegetable-dragon\\model\\han_env\\lib\\site-packages (from cmudict->kss) (8.7.0)\n",
      "Requirement already satisfied: importlib-resources>=5 in e:\\vegetable-dragon\\model\\han_env\\lib\\site-packages (from cmudict->kss) (6.5.2)\n",
      "Requirement already satisfied: whoosh in e:\\vegetable-dragon\\model\\han_env\\lib\\site-packages (from kollocate->kss) (2.7.4)\n",
      "Requirement already satisfied: xlrd==1.2.0 in e:\\vegetable-dragon\\model\\han_env\\lib\\site-packages (from koparadigm->kss) (1.2.0)\n",
      "Requirement already satisfied: pyarrow in e:\\vegetable-dragon\\model\\han_env\\lib\\site-packages (from pecab->kss) (20.0.0)\n",
      "Requirement already satisfied: regex in e:\\vegetable-dragon\\model\\han_env\\lib\\site-packages (from pecab->kss) (2024.11.6)\n",
      "Requirement already satisfied: iniconfig in e:\\vegetable-dragon\\model\\han_env\\lib\\site-packages (from pytest->kss) (2.1.0)\n",
      "Requirement already satisfied: packaging in e:\\vegetable-dragon\\model\\han_env\\lib\\site-packages (from pytest->kss) (25.0)\n",
      "Requirement already satisfied: pluggy<2,>=1.5 in e:\\vegetable-dragon\\model\\han_env\\lib\\site-packages (from pytest->kss) (1.6.0)\n",
      "Requirement already satisfied: bidict in e:\\vegetable-dragon\\model\\han_env\\lib\\site-packages (from tossi->kss) (0.23.1)\n",
      "Requirement already satisfied: six in e:\\vegetable-dragon\\model\\han_env\\lib\\site-packages (from tossi->kss) (1.17.0)\n",
      "Requirement already satisfied: zipp>=3.20 in e:\\vegetable-dragon\\model\\han_env\\lib\\site-packages (from importlib-metadata>=5->cmudict->kss) (3.21.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in e:\\vegetable-dragon\\model\\han_env\\lib\\site-packages (from beautifulsoup4->bs4->kss) (2.7)\n",
      "Using cached flask-3.1.1-py3-none-any.whl (103 kB)\n",
      "Using cached bs4-0.0.2-py2.py3-none-any.whl (1.2 kB)\n",
      "Using cached cmudict-1.0.32-py3-none-any.whl (939 kB)\n",
      "Installing collected packages: pecab, flask, cmudict, bs4, kss\n",
      "Successfully installed bs4-0.0.2 cmudict-1.0.32 flask-3.1.1 kss-6.0.4 pecab-1.0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ngrok tunnel URL: NgrokTunnel: \"https://1989-218-237-232-179.ngrok-free.app\" -> \"http://localhost:5000\"\n",
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Kss]: \u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on http://127.0.0.1:5000\n",
      "[Kss]: \u001b[33mPress CTRL+C to quit\u001b[0m\n",
      "[Kss]: Because there's no supported C++ morpheme analyzer, Kss will take pecab as a backend. :D\n",
      "For your information, Kss also supports mecab backend.\n",
      "We recommend you to install mecab or konlpy.tag.Mecab for faster execution of Kss.\n",
      "Please refer to following web sites for details:\n",
      "- mecab: https://cleancode-ws.tistory.com/97\n",
      "- konlpy.tag.Mecab: https://uwgdqo.tistory.com/363\n",
      "\n",
      "[Kss]: 127.0.0.1 - - [18/May/2025 01:36:02] \"POST /predict HTTP/1.1\" 200 -\n",
      "[Kss]: 127.0.0.1 - - [18/May/2025 01:36:03] \"POST /predict HTTP/1.1\" 200 -\n",
      "E:\\vegetable-dragon\\model\\han_env\\Lib\\site-packages\\pecab\\_tokenizer.py:265: RuntimeWarning: overflow encountered in scalar add\n",
      "  from_pos_data.costs[idx]\n",
      "[Kss]: Exception on /predict [POST]\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\vegetable-dragon\\model\\han_env\\Lib\\site-packages\\flask\\app.py\", line 1511, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\vegetable-dragon\\model\\han_env\\Lib\\site-packages\\flask\\app.py\", line 919, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\vegetable-dragon\\model\\han_env\\Lib\\site-packages\\flask\\app.py\", line 917, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\vegetable-dragon\\model\\han_env\\Lib\\site-packages\\flask\\app.py\", line 902, in dispatch_request\n",
      "    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\82108\\AppData\\Local\\Temp\\ipykernel_29072\\3239984884.py\", line 112, in predict\n",
      "    input_tensor = encode_korean(full_text).unsqueeze(0).to(device)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\82108\\AppData\\Local\\Temp\\ipykernel_29072\\3239984884.py\", line 91, in encode_korean\n",
      "    sents = kss.split_sentences(str(text))[:SENT_MAXLEN]\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\vegetable-dragon\\model\\han_env\\Lib\\site-packages\\kss\\_modules\\sentences\\split_sentences.py\", line 88, in split_sentences\n",
      "    return _run_job(\n",
      "           ^^^^^^^^^\n",
      "  File \"E:\\vegetable-dragon\\model\\han_env\\Lib\\site-packages\\kss\\_utils\\multiprocessing.py\", line 26, in _run_job\n",
      "    output = func(inputs)\n",
      "             ^^^^^^^^^^^^\n",
      "  File \"E:\\vegetable-dragon\\model\\han_env\\Lib\\site-packages\\kss\\_modules\\sentences\\split_sentences.py\", line 135, in _split_sentences\n",
      "    morphemes = backend.pos(backup_sentence, drop_space=False)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\vegetable-dragon\\model\\han_env\\Lib\\site-packages\\kss\\_modules\\morphemes\\analyzers.py\", line 64, in pos\n",
      "    output = self._analyzer.pos(text)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\vegetable-dragon\\model\\han_env\\Lib\\site-packages\\pecab\\_pecab.py\", line 45, in pos\n",
      "    tokenization_output = self._tokenize(text)\n",
      "                          ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\vegetable-dragon\\model\\han_env\\Lib\\site-packages\\pecab\\_pecab.py\", line 19, in _tokenize\n",
      "    while self.tokenizer.increment_token():\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\vegetable-dragon\\model\\han_env\\Lib\\site-packages\\pecab\\_tokenizer.py\", line 292, in increment_token\n",
      "    self.parse()\n",
      "  File \"E:\\vegetable-dragon\\model\\han_env\\Lib\\site-packages\\pecab\\_tokenizer.py\", line 467, in parse\n",
      "    self.backtrace(end_pos_data, least_idx)\n",
      "  File \"E:\\vegetable-dragon\\model\\han_env\\Lib\\site-packages\\pecab\\_tokenizer.py\", line 478, in backtrace\n",
      "    back_pos = pos_data.back_pos[best_idx]\n",
      "               ~~~~~~~~~~~~~~~~~^^^^^^^^^^\n",
      "IndexError: list index out of range\n",
      "[Kss]: Exception on /predict [POST]\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\vegetable-dragon\\model\\han_env\\Lib\\site-packages\\flask\\app.py\", line 1511, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\vegetable-dragon\\model\\han_env\\Lib\\site-packages\\flask\\app.py\", line 919, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\vegetable-dragon\\model\\han_env\\Lib\\site-packages\\flask\\app.py\", line 917, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\vegetable-dragon\\model\\han_env\\Lib\\site-packages\\flask\\app.py\", line 902, in dispatch_request\n",
      "    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\82108\\AppData\\Local\\Temp\\ipykernel_29072\\3239984884.py\", line 112, in predict\n",
      "    input_tensor = encode_korean(full_text).unsqueeze(0).to(device)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\82108\\AppData\\Local\\Temp\\ipykernel_29072\\3239984884.py\", line 91, in encode_korean\n",
      "    sents = kss.split_sentences(str(text))[:SENT_MAXLEN]\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\vegetable-dragon\\model\\han_env\\Lib\\site-packages\\kss\\_modules\\sentences\\split_sentences.py\", line 88, in split_sentences\n",
      "    return _run_job(\n",
      "           ^^^^^^^^^\n",
      "  File \"E:\\vegetable-dragon\\model\\han_env\\Lib\\site-packages\\kss\\_utils\\multiprocessing.py\", line 26, in _run_job\n",
      "    output = func(inputs)\n",
      "             ^^^^^^^^^^^^\n",
      "  File \"E:\\vegetable-dragon\\model\\han_env\\Lib\\site-packages\\kss\\_modules\\sentences\\split_sentences.py\", line 135, in _split_sentences\n",
      "    morphemes = backend.pos(backup_sentence, drop_space=False)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\vegetable-dragon\\model\\han_env\\Lib\\site-packages\\kss\\_modules\\morphemes\\analyzers.py\", line 64, in pos\n",
      "    output = self._analyzer.pos(text)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\vegetable-dragon\\model\\han_env\\Lib\\site-packages\\pecab\\_pecab.py\", line 45, in pos\n",
      "    tokenization_output = self._tokenize(text)\n",
      "                          ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\vegetable-dragon\\model\\han_env\\Lib\\site-packages\\pecab\\_pecab.py\", line 19, in _tokenize\n",
      "    while self.tokenizer.increment_token():\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\vegetable-dragon\\model\\han_env\\Lib\\site-packages\\pecab\\_tokenizer.py\", line 292, in increment_token\n",
      "    self.parse()\n",
      "  File \"E:\\vegetable-dragon\\model\\han_env\\Lib\\site-packages\\pecab\\_tokenizer.py\", line 467, in parse\n",
      "    self.backtrace(end_pos_data, least_idx)\n",
      "  File \"E:\\vegetable-dragon\\model\\han_env\\Lib\\site-packages\\pecab\\_tokenizer.py\", line 478, in backtrace\n",
      "    back_pos = pos_data.back_pos[best_idx]\n",
      "               ~~~~~~~~~~~~~~~~~^^^^^^^^^^\n",
      "IndexError: list index out of range\n",
      "[Kss]: 127.0.0.1 - - [18/May/2025 01:44:54] \"\u001b[35m\u001b[1mPOST /predict HTTP/1.1\u001b[0m\" 500 -\n",
      "[Kss]: 127.0.0.1 - - [18/May/2025 01:44:54] \"\u001b[35m\u001b[1mPOST /predict HTTP/1.1\u001b[0m\" 500 -\n",
      "[Kss]: 127.0.0.1 - - [18/May/2025 01:44:57] \"POST /predict HTTP/1.1\" 200 -\n",
      "[Kss]: 127.0.0.1 - - [18/May/2025 01:47:34] \"\u001b[31m\u001b[1mPOST /predict HTTP/1.1\u001b[0m\" 400 -\n",
      "[Kss]: 127.0.0.1 - - [18/May/2025 01:57:12] \"POST /predict HTTP/1.1\" 200 -\n",
      "[Kss]: 127.0.0.1 - - [18/May/2025 02:13:42] \"POST /predict HTTP/1.1\" 200 -\n",
      "[Kss]: Exception on /predict [POST]\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\vegetable-dragon\\model\\han_env\\Lib\\site-packages\\flask\\app.py\", line 1511, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\vegetable-dragon\\model\\han_env\\Lib\\site-packages\\flask\\app.py\", line 919, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\vegetable-dragon\\model\\han_env\\Lib\\site-packages\\flask\\app.py\", line 917, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\vegetable-dragon\\model\\han_env\\Lib\\site-packages\\flask\\app.py\", line 902, in dispatch_request\n",
      "    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\82108\\AppData\\Local\\Temp\\ipykernel_29072\\3239984884.py\", line 112, in predict\n",
      "    input_tensor = encode_korean(full_text).unsqueeze(0).to(device)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\82108\\AppData\\Local\\Temp\\ipykernel_29072\\3239984884.py\", line 91, in encode_korean\n",
      "    sents = kss.split_sentences(str(text))[:SENT_MAXLEN]\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\vegetable-dragon\\model\\han_env\\Lib\\site-packages\\kss\\_modules\\sentences\\split_sentences.py\", line 88, in split_sentences\n",
      "    return _run_job(\n",
      "           ^^^^^^^^^\n",
      "  File \"E:\\vegetable-dragon\\model\\han_env\\Lib\\site-packages\\kss\\_utils\\multiprocessing.py\", line 26, in _run_job\n",
      "    output = func(inputs)\n",
      "             ^^^^^^^^^^^^\n",
      "  File \"E:\\vegetable-dragon\\model\\han_env\\Lib\\site-packages\\kss\\_modules\\sentences\\split_sentences.py\", line 135, in _split_sentences\n",
      "    morphemes = backend.pos(backup_sentence, drop_space=False)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\vegetable-dragon\\model\\han_env\\Lib\\site-packages\\kss\\_modules\\morphemes\\analyzers.py\", line 64, in pos\n",
      "    output = self._analyzer.pos(text)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\vegetable-dragon\\model\\han_env\\Lib\\site-packages\\pecab\\_pecab.py\", line 45, in pos\n",
      "    tokenization_output = self._tokenize(text)\n",
      "                          ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\vegetable-dragon\\model\\han_env\\Lib\\site-packages\\pecab\\_pecab.py\", line 19, in _tokenize\n",
      "    while self.tokenizer.increment_token():\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\vegetable-dragon\\model\\han_env\\Lib\\site-packages\\pecab\\_tokenizer.py\", line 292, in increment_token\n",
      "    self.parse()\n",
      "  File \"E:\\vegetable-dragon\\model\\han_env\\Lib\\site-packages\\pecab\\_tokenizer.py\", line 467, in parse\n",
      "    self.backtrace(end_pos_data, least_idx)\n",
      "  File \"E:\\vegetable-dragon\\model\\han_env\\Lib\\site-packages\\pecab\\_tokenizer.py\", line 478, in backtrace\n",
      "    back_pos = pos_data.back_pos[best_idx]\n",
      "               ~~~~~~~~~~~~~~~~~^^^^^^^^^^\n",
      "IndexError: list index out of range\n",
      "[Kss]: Exception on /predict [POST]\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\vegetable-dragon\\model\\han_env\\Lib\\site-packages\\flask\\app.py\", line 1511, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\vegetable-dragon\\model\\han_env\\Lib\\site-packages\\flask\\app.py\", line 919, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\vegetable-dragon\\model\\han_env\\Lib\\site-packages\\flask\\app.py\", line 917, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\vegetable-dragon\\model\\han_env\\Lib\\site-packages\\flask\\app.py\", line 902, in dispatch_request\n",
      "    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\82108\\AppData\\Local\\Temp\\ipykernel_29072\\3239984884.py\", line 112, in predict\n",
      "    input_tensor = encode_korean(full_text).unsqueeze(0).to(device)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\82108\\AppData\\Local\\Temp\\ipykernel_29072\\3239984884.py\", line 91, in encode_korean\n",
      "    sents = kss.split_sentences(str(text))[:SENT_MAXLEN]\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\vegetable-dragon\\model\\han_env\\Lib\\site-packages\\kss\\_modules\\sentences\\split_sentences.py\", line 88, in split_sentences\n",
      "    return _run_job(\n",
      "           ^^^^^^^^^\n",
      "  File \"E:\\vegetable-dragon\\model\\han_env\\Lib\\site-packages\\kss\\_utils\\multiprocessing.py\", line 26, in _run_job\n",
      "    output = func(inputs)\n",
      "             ^^^^^^^^^^^^\n",
      "  File \"E:\\vegetable-dragon\\model\\han_env\\Lib\\site-packages\\kss\\_modules\\sentences\\split_sentences.py\", line 135, in _split_sentences\n",
      "    morphemes = backend.pos(backup_sentence, drop_space=False)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\vegetable-dragon\\model\\han_env\\Lib\\site-packages\\kss\\_modules\\morphemes\\analyzers.py\", line 64, in pos\n",
      "    output = self._analyzer.pos(text)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\vegetable-dragon\\model\\han_env\\Lib\\site-packages\\pecab\\_pecab.py\", line 45, in pos\n",
      "    tokenization_output = self._tokenize(text)\n",
      "                          ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\vegetable-dragon\\model\\han_env\\Lib\\site-packages\\pecab\\_pecab.py\", line 19, in _tokenize\n",
      "    while self.tokenizer.increment_token():\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\vegetable-dragon\\model\\han_env\\Lib\\site-packages\\pecab\\_tokenizer.py\", line 292, in increment_token\n",
      "    self.parse()\n",
      "  File \"E:\\vegetable-dragon\\model\\han_env\\Lib\\site-packages\\pecab\\_tokenizer.py\", line 467, in parse\n",
      "    self.backtrace(end_pos_data, least_idx)\n",
      "  File \"E:\\vegetable-dragon\\model\\han_env\\Lib\\site-packages\\pecab\\_tokenizer.py\", line 478, in backtrace\n",
      "    back_pos = pos_data.back_pos[best_idx]\n",
      "               ~~~~~~~~~~~~~~~~~^^^^^^^^^^\n",
      "IndexError: list index out of range\n",
      "[Kss]: 127.0.0.1 - - [18/May/2025 02:14:30] \"\u001b[35m\u001b[1mPOST /predict HTTP/1.1\u001b[0m\" 500 -\n",
      "[Kss]: 127.0.0.1 - - [18/May/2025 02:14:30] \"\u001b[35m\u001b[1mPOST /predict HTTP/1.1\u001b[0m\" 500 -\n",
      "[Kss]: 127.0.0.1 - - [18/May/2025 02:14:33] \"POST /predict HTTP/1.1\" 200 -\n",
      "[Kss]: 127.0.0.1 - - [18/May/2025 02:15:49] \"POST /predict HTTP/1.1\" 200 -\n",
      "E:\\vegetable-dragon\\model\\han_env\\Lib\\site-packages\\pecab\\_tokenizer.py:274: RuntimeWarning: overflow encountered in scalar add\n",
      "  least_cost += word_cost\n",
      "[Kss]: 127.0.0.1 - - [18/May/2025 02:16:25] \"POST /predict HTTP/1.1\" 200 -\n",
      "[Kss]: 127.0.0.1 - - [18/May/2025 02:17:40] \"POST /predict HTTP/1.1\" 200 -\n",
      "[Kss]: 127.0.0.1 - - [18/May/2025 02:18:11] \"\u001b[31m\u001b[1mPOST /predict HTTP/1.1\u001b[0m\" 400 -\n",
      "[Kss]: 127.0.0.1 - - [18/May/2025 02:18:51] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "!pip install flask pyngrok torch kss\n",
    "\n",
    "from flask import Flask, request, jsonify\n",
    "from pyngrok import ngrok\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import kss\n",
    "import pickle\n",
    "\n",
    "# ===== HAN 모델 클래스 정의 =====\n",
    "class WordAttention(nn.Module):\n",
    "    def __init__(self, embed_size, hidden_size):\n",
    "        super().__init__()\n",
    "        self.gru = nn.GRU(embed_size, hidden_size, bidirectional=True, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size * 2, hidden_size * 2)\n",
    "        self.context = nn.Parameter(torch.randn(hidden_size * 2))\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.gru(x)\n",
    "        u = torch.tanh(self.fc(out))\n",
    "        attn = torch.matmul(u, self.context)\n",
    "        attn = F.softmax(attn, dim=1).unsqueeze(-1)\n",
    "        s = torch.sum(out * attn, dim=1)\n",
    "        return s\n",
    "\n",
    "class SentenceAttention(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super().__init__()\n",
    "        self.gru = nn.GRU(hidden_size * 2, hidden_size, bidirectional=True, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size * 2, hidden_size * 2)\n",
    "        self.context = nn.Parameter(torch.randn(hidden_size * 2))\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.gru(x)\n",
    "        u = torch.tanh(self.fc(out))\n",
    "        attn = torch.matmul(u, self.context)\n",
    "        attn = F.softmax(attn, dim=1).unsqueeze(-1)\n",
    "        v = torch.sum(out * attn, dim=1)\n",
    "        return v\n",
    "\n",
    "class HAN(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size=128, hidden_size=64, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size, padding_idx=0)\n",
    "        self.word_attn = WordAttention(embed_size, hidden_size)\n",
    "        self.sen_attn = SentenceAttention(hidden_size)\n",
    "        self.fc = nn.Linear(hidden_size * 2, num_classes)\n",
    "\n",
    "    def forward(self, x):  # x: (B, S, W)\n",
    "        B, S, W = x.shape\n",
    "        sents = []\n",
    "        for s in range(S):\n",
    "            e = self.embedding(x[:, s, :])  # (B, W, E)\n",
    "            s_vec = self.word_attn(e)       # (B, H*2)\n",
    "            sents.append(s_vec)\n",
    "        s_mat = torch.stack(sents, dim=1)   # (B, S, H*2)\n",
    "        doc_vec = self.sen_attn(s_mat)      # (B, H*2)\n",
    "        out = self.fc(doc_vec)              # (B, C)\n",
    "        return out\n",
    "\n",
    "# ===== Flask 앱 초기화 =====\n",
    "app = Flask(__name__)\n",
    "\n",
    "# ===== 모델 및 vocab 로드 =====\n",
    "device = torch.device(\"cpu\")\n",
    "model_path = \"han_model_cpu.pkl\"\n",
    "\n",
    "# pickle로 저장된 파일 불러오기\n",
    "with open(model_path, 'rb') as f:\n",
    "    saved = pickle.load(f)\n",
    "\n",
    "vocab = saved['vocab']\n",
    "config = saved['config']\n",
    "\n",
    "model = HAN(\n",
    "    vocab_size=len(vocab),\n",
    "    embed_size=config['embed_size'],\n",
    "    hidden_size=config['hidden_size'],\n",
    "    num_classes=config['num_classes']\n",
    ")\n",
    "model.load_state_dict(saved['model_state'])\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# ===== 전처리 함수 =====\n",
    "def encode_korean(text):\n",
    "    SENT_MAXLEN = config['SENT_MAXLEN']\n",
    "    WORD_MAXLEN = config['WORD_MAXLEN']\n",
    "\n",
    "    sents = kss.split_sentences(str(text))[:SENT_MAXLEN]\n",
    "    doc_idx = []\n",
    "    for sent in sents:\n",
    "        word_idx = [vocab.get(w, 1) for w in sent.split()[:WORD_MAXLEN]]\n",
    "        word_idx += [0] * (WORD_MAXLEN - len(word_idx))\n",
    "        doc_idx.append(word_idx)\n",
    "    while len(doc_idx) < SENT_MAXLEN:\n",
    "        doc_idx.append([0]*WORD_MAXLEN)\n",
    "    return torch.tensor(doc_idx, dtype=torch.long)\n",
    "\n",
    "# ===== 예측 API =====\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    data = request.json\n",
    "    title = data.get(\"title\", \"\")\n",
    "    content = data.get(\"content\", \"\")\n",
    "\n",
    "    if not title and not content:\n",
    "        return jsonify({'error': '입력 텍스트가 없습니다.'}), 400\n",
    "\n",
    "    full_text = f\"{title} {content}\".strip()\n",
    "    input_tensor = encode_korean(full_text).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(input_tensor)\n",
    "        probs = torch.softmax(output, dim=1)[0].tolist()  # 확률 계산\n",
    "        pred = output.argmax().item()\n",
    "\n",
    "    return jsonify({\n",
    "        'prediction': pred,\n",
    "        'probabilities': {\n",
    "            'class_0': round(probs[0]*100, 2),\n",
    "            'class_1': round(probs[1]*100, 2)\n",
    "        }\n",
    "    })\n",
    "    \n",
    "# ===== 루트 안내 메시지 =====\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return \"HAN 모델 API입니다. POST /predict로 'title'과 'content'를 보내주세요.\", 200\n",
    "\n",
    "# ===== 서버 실행 및 ngrok 연결 =====\n",
    "if __name__ == '__main__':\n",
    "    AUTH_TOKEN = \"2tZphsq6YON5WdcRN6sWph8myF0_7Mk72ZnK7h8x42QkSS85P\"\n",
    "    ngrok.set_auth_token(AUTH_TOKEN)\n",
    "    public_url = ngrok.connect(5000)\n",
    "    print(\"ngrok tunnel URL:\", public_url)\n",
    "    app.run(port=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ab2a7b-f202-4a79-9fdf-e4a71246fc4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (HAN)",
   "language": "python",
   "name": "han-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
