{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52ea2581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ngrok tunnel URL: NgrokTunnel: \"https://c8bc-166-104-245-67.ngrok-free.app\" -> \"http://localhost:5000\"\n",
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Kss]: \u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on http://127.0.0.1:5000\n",
      "[Kss]: \u001b[33mPress CTRL+C to quit\u001b[0m\n",
      "d:\\대학\\캡스톤\\vegetable_dragon\\model\\.venv\\Lib\\site-packages\\pecab\\_tokenizer.py:265: RuntimeWarning: overflow encountered in scalar add\n",
      "  from_pos_data.costs[idx]\n",
      "[Kss]: 127.0.0.1 - - [15/May/2025 19:33:47] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "from pyngrok import ngrok\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import kss\n",
    "import pickle\n",
    "\n",
    "# ===== HAN 모델 클래스 정의 =====\n",
    "class WordAttention(nn.Module):\n",
    "    def __init__(self, embed_size, hidden_size):\n",
    "        super().__init__()\n",
    "        self.gru = nn.GRU(embed_size, hidden_size, bidirectional=True, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size * 2, hidden_size * 2)\n",
    "        self.context = nn.Parameter(torch.randn(hidden_size * 2))\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.gru(x)\n",
    "        u = torch.tanh(self.fc(out))\n",
    "        attn = torch.matmul(u, self.context)\n",
    "        attn = F.softmax(attn, dim=1).unsqueeze(-1)\n",
    "        s = torch.sum(out * attn, dim=1)\n",
    "        return s\n",
    "\n",
    "class SentenceAttention(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super().__init__()\n",
    "        self.gru = nn.GRU(hidden_size * 2, hidden_size, bidirectional=True, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size * 2, hidden_size * 2)\n",
    "        self.context = nn.Parameter(torch.randn(hidden_size * 2))\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.gru(x)\n",
    "        u = torch.tanh(self.fc(out))\n",
    "        attn = torch.matmul(u, self.context)\n",
    "        attn = F.softmax(attn, dim=1).unsqueeze(-1)\n",
    "        v = torch.sum(out * attn, dim=1)\n",
    "        return v\n",
    "\n",
    "class HAN(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size=128, hidden_size=64, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size, padding_idx=0)\n",
    "        self.word_attn = WordAttention(embed_size, hidden_size)\n",
    "        self.sen_attn = SentenceAttention(hidden_size)\n",
    "        self.fc = nn.Linear(hidden_size * 2, num_classes)\n",
    "\n",
    "    def forward(self, x):  # x: (B, S, W)\n",
    "        B, S, W = x.shape\n",
    "        sents = []\n",
    "        for s in range(S):\n",
    "            e = self.embedding(x[:, s, :])  # (B, W, E)\n",
    "            s_vec = self.word_attn(e)       # (B, H*2)\n",
    "            sents.append(s_vec)\n",
    "        s_mat = torch.stack(sents, dim=1)   # (B, S, H*2)\n",
    "        doc_vec = self.sen_attn(s_mat)      # (B, H*2)\n",
    "        out = self.fc(doc_vec)              # (B, C)\n",
    "        return out\n",
    "\n",
    "# ===== Flask 앱 초기화 =====\n",
    "app = Flask(__name__)\n",
    "\n",
    "# ===== 모델 및 vocab 로드 =====\n",
    "device = torch.device(\"cpu\")\n",
    "model_path = \"han_model_cpu.pkl\"\n",
    "\n",
    "# pickle로 저장된 파일 불러오기\n",
    "with open(model_path, 'rb') as f:\n",
    "    saved = pickle.load(f)\n",
    "\n",
    "vocab = saved['vocab']\n",
    "config = saved['config']\n",
    "\n",
    "model = HAN(\n",
    "    vocab_size=len(vocab),\n",
    "    embed_size=config['embed_size'],\n",
    "    hidden_size=config['hidden_size'],\n",
    "    num_classes=config['num_classes']\n",
    ")\n",
    "model.load_state_dict(saved['model_state'])\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# ===== 전처리 함수 =====\n",
    "def encode_korean(text):\n",
    "    SENT_MAXLEN = config['SENT_MAXLEN']\n",
    "    WORD_MAXLEN = config['WORD_MAXLEN']\n",
    "\n",
    "    sents = kss.split_sentences(str(text))[:SENT_MAXLEN]\n",
    "    doc_idx = []\n",
    "    for sent in sents:\n",
    "        word_idx = [vocab.get(w, 1) for w in sent.split()[:WORD_MAXLEN]]\n",
    "        word_idx += [0] * (WORD_MAXLEN - len(word_idx))\n",
    "        doc_idx.append(word_idx)\n",
    "    while len(doc_idx) < SENT_MAXLEN:\n",
    "        doc_idx.append([0]*WORD_MAXLEN)\n",
    "    return torch.tensor(doc_idx, dtype=torch.long)\n",
    "\n",
    "# ===== 예측 API =====\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    data = request.json\n",
    "    title = data.get(\"title\", \"\")\n",
    "    content = data.get(\"content\", \"\")\n",
    "\n",
    "    if not title and not content:\n",
    "        return jsonify({'error': '입력 텍스트가 없습니다.'}), 400\n",
    "\n",
    "    # 제목과 내용을 공백으로 결합\n",
    "    full_text = f\"{title} {content}\".strip()\n",
    "\n",
    "    input_tensor = encode_korean(full_text).unsqueeze(0).to(device)  # (1, S, W)\n",
    "    with torch.no_grad():\n",
    "        output = model(input_tensor)\n",
    "        pred = output.argmax(dim=1).item()\n",
    "\n",
    "    return jsonify({'prediction': pred})\n",
    "\n",
    "# ===== 루트 안내 메시지 =====\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return \"HAN 모델 API입니다. POST /predict로 'title'과 'content'를 보내주세요.\", 200\n",
    "\n",
    "# ===== 서버 실행 및 ngrok 연결 =====\n",
    "if __name__ == '__main__':\n",
    "    ngrok.set_auth_token(\"2x5IsONJiTj67Ld0Yqmk4v60JCa_76yj4k9eBbT2wB8gxZweB\")\n",
    "    public_url = ngrok.connect(5000)\n",
    "    print(\"ngrok tunnel URL:\", public_url)\n",
    "    app.run(port=5000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
